

We have an input image with 256 channels of size 228 x 228.

The intermediate image after the convolution layer is 224 x 224 with 256 channels.
    224 because each window that we apply a filter to is 5 x 5. 
    The element in the center of the window is essentially the position of the output pixel so we lose the 2 unit width frame around it.

We max pool a 2 x 2 tile (pool size) so we get a 112 x 112 image with 256 channels in the end.

Convolution Layer

    LOOP 1: Set bias for each channel    
        We have 256 biases, one for each channel.

    LOOP 2: Perform Convolution 
        Multiply element in window of image with corresponding element in filter; window is 5 x 5.
        We have 256 filters. Each filter has 256 channels. Each filter is size 5 x 5.

    LOOP 3: Perform ReLU 
        Take max of convolution product + bias and 0.

Max Pooling Layer

    LOOP 4: Perform Max Pooling
        Take 4 pixels (in a 2 x 2 tile) and for each of the 256 channel, we take the max value of those 4 pixels.


1. Reduce memory usage
- Loop fusion
    We reduce memory usage by cutting C down to 2 dimensions.
    Before, we stored the output for each channel of the intermediate array to its own part of C, given that the array had a third dimension to store each channel.
    Now, we fuse the loop, so that we instead just rewrite C on each iteration of i (which is each channel), and write to the output array before moving on to the next channel.
- Loop tiling
    Reduce memory usage further by only writing portions of the C array at a time. We process only a tile of the C array at a time by tiling h and w.


Tests:
4 x 32
'56 7'
'4 1'
    191.77 GFlops
    190.342 GFlops
    188.683 GFlops

4 x 16
'56 14'
'4 2'
    183.975 GFlops
    183.488 GFlops
    182.515 GFlops

4 x 8
'56 28'
'4 4'
    91.6593 GFlops
    91.1012 GFlops
    91.3293 GFlops

4 x 4
'56 56'
'4 8'
    45.9411 GFlops
    45.9159 GFlops
    45.9918 GFlops

4 x 2
'56 112'
'4 16'
    22.7137 GFlops
    22.5103 GFlops
    22.9142 GFlops

2 x 2
'112 112'
'8 16'
    22.1707 GFlops
    22.3999 GFlops
    22.401 GFlops

    
    