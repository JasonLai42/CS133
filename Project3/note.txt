

We have an input image with 256 channels of size 228 x 228.

The intermediate image after the convolution layer is 224 x 224 with 256 channels.
    224 because each window that we apply a filter to is 5 x 5. 
    The element in the center of the window is essentially the position of the output pixel so we lose the 2 unit width frame around it.

We max pool a 2 x 2 tile (pool size) so we get a 112 x 112 image with 256 channels in the end.

Convolution Layer

    LOOP 1: Set bias for each channel    
        We have 256 biases, one for each channel.

    LOOP 2: Perform Convolution 
        Multiply element in window of image with corresponding element in filter; window is 5 x 5.
        We have 256 filters. Each filter has 256 channels. Each filter is size 5 x 5.

    LOOP 3: Perform ReLU 
        Take max of convolution product + bias and 0.

Max Pooling Layer

    LOOP 4: Perform Max Pooling
        Take 4 pixels (in a 2 x 2 tile) and for each of the 256 channel, we take the max value of those 4 pixels.


1. Reduce memory usage
- Loop fusion
    We reduce memory usage by cutting C down to 2 dimensions.
    Before, we stored the output for each channel of the intermediate array to its own part of C, given that the array had a third dimension to store each channel.
    Now, we fuse the loop, so that we instead just rewrite C on each iteration of i (which is each channel), and write to the output array before moving on to the next channel.
- Loop tiling
    Reduce memory usage further by only writing portions of the C array at a time. We process only a tile of the C array at a time by tiling h and w.


Tests:
Sequential
    14.2738 s
    11.5188 GFlops
    14.2869 s
    11.5083 GFlops
    14.2691 s
    11.5225 GFlops

4 x 32
'56 7'
'4 1'
    0.868481 s
    189.315 GFlops
    0.868096 s
    189.399 GFlops
    0.868619 s
    189.285 GFlops

4 x 16
'56 14'
'4 2'
    0.90647 s
    181.381 GFlops
    0.907966 s
    181.082 GFlops
    0.914513 s
    179.786 GFlops

4 x 8
'56 28'
'4 4'
    1.79938 s
    91.3743 GFlops
    1.81787 s
    90.4445 GFlops
    1.89362 s
    86.8267 GFlops

4 x 4
'56 56'
'4 8'
    3.64899 s
    45.0581 GFlops
    3.63626 s
    45.2159 GFlops
    3.67188 s
    44.7772 GFlops

4 x 2
'56 112'
'4 16'
    7.3416 s
    22.3952 GFlops
    7.3092 s
    22.4945 GFlops
    7.22553 s
    22.755 GFlops

2 x 2
'112 112'
'8 16'
    7.40242 s
    22.2112 GFlops
    7.46604 s
    22.0219 GFlops
    7.43644 s
    22.1096 GFlops
    