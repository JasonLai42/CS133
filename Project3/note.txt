

We have an input image with 256 channels of size 228 x 228.

The intermediate image after the convolution layer is 224 x 224 with 256 channels.
    224 because each window that we apply a filter to is 5 x 5. 
    The element in the center of the window is essentially the position of the output pixel so we lose the 2 unit width frame around it.

We max pool a 2 x 2 tile (pool size) so we get a 112 x 112 image with 256 channels in the end.

Convolution Layer

    LOOP 1: Set bias for each channel    
        We have 256 biases, one for each channel.

    LOOP 2: Perform Convolution 
        Multiply element in window of image with corresponding element in filter; window is 5 x 5.
        We have 256 filters. Each filter has 256 channels. Each filter is size 5 x 5.

    LOOP 3: Perform ReLU 
        Take max of convolution product + bias and 0.

Max Pooling Layer

    LOOP 4: Perform Max Pooling
        Take 4 pixels (in a 2 x 2 tile) and for each of the 256 channel, we take the max value of those 4 pixels.


1. Reduce memory usage
- Loop fusion
    We reduce memory usage by cutting C down to 2 dimensions.
    Before, we stored the output for each channel of the intermediate array to its own part of C, given that the array had a third dimension to store each channel.
    Now, we fuse the loop, so that we instead just rewrite C on each iteration of i (which is each channel), and write to the output array before moving on to the next channel.
- Loop tiling
    Reduce memory usage further by only writing portions of the C array at a time. We process only a tile of the C array at a time by tiling h and w.